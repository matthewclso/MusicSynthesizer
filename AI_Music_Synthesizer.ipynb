{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Music Synthesizer",
      "provenance": [],
      "collapsed_sections": [
        "tyAZm9ojfNa2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyAZm9ojfNa2"
      },
      "source": [
        "# **Downloading and organizing the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLxfGNIfCxvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "93aa7b89-97ac-46bc-a16f-1b88be020f8c"
      },
      "source": [
        "import numpy as np\n",
        "import os, csv\n",
        "import io\n",
        "import tarfile, zipfile\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(path)\n",
        "import musicnet\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1c581d99b889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"My Drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AI Music Synthesizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmusicnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/AI Music Synthesizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebx_hzaFKfS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b6b87391-bd3e-482d-bf37-96b9fa114808"
      },
      "source": [
        "# Ensure directories are empty\n",
        "os.chdir(\"/content\")\n",
        "os.chdir(os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\"))\n",
        "!rm -rf \"homes.cs.washington.edu\"\n",
        "!rm -rf \"github.com\"\n",
        "os.chdir(\"/content\")\n",
        "!rm -rf \"/content/musicnet\"\n",
        "!rm -rf \"/content/pytorch_musicnet-master\"\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d2a273adf0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ensure directories are empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"My Drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AI Music Synthesizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf \"homes.cs.washington.edu\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf \"github.com\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/AI Music Synthesizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToHKRlfBBygL"
      },
      "source": [
        "# Download data\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(path)\n",
        "!wget -r -nc -A tar.gz https://homes.cs.washington.edu/~thickstn/media/musicnet.tar.gz\n",
        "!wget -r -nc -A zip https://github.com/jthickstun/pytorch_musicnet/archive/master.zip\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEI6pmmL0hh5"
      },
      "source": [
        "# Extract data\n",
        "class ProgressFileObject(io.FileIO):\n",
        "    def __init__(self, path, *args, **kwargs):\n",
        "        self._total_size = os.path.getsize(path)\n",
        "        io.FileIO.__init__(self, path, *args, **kwargs)\n",
        "\n",
        "    def read(self, size):\n",
        "        print(\"Extract process: \", \"{:.3f}\".format(100 * (self.tell() / self._total_size)), \" %\")\n",
        "        return io.FileIO.read(self, size)\n",
        "\n",
        "tarfile.TarFile.fileobject = get_file_progress_file_object_class(on_progress)\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\", \"homes.cs.washington.edu\", \"~thickstn\", \"media\")\n",
        "os.chdir(path)\n",
        "with tarfile.open(fileobj = ProgressFileObject(\"musicnet.tar.gz\")) as tar:\n",
        "  tar.extractall(path = \"/content\")\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\", \"github.com\", \"jthickstun\", \"pytorch_musicnet\", \"archive\")\n",
        "os.chdir(path)\n",
        "with zipfile.ZipFile(\"master.zip\") as zip_ref:\n",
        "  zip_ref.extractall(path = \"/content\")\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"pytorch_musicnet-master\")\n",
        "os.chdir(path)\n",
        "import musicnet\n",
        "\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP8fz99Ymo7M"
      },
      "source": [
        "# Only use solo piano pieces\n",
        "os.chdir(\"/content\")\n",
        "metadata_dir = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(metadata_dir)\n",
        "piano_pieces = []\n",
        "with open(\"musicnet_metadata.csv\") as metadata_file:\n",
        "  reader = csv.reader(metadata_file, delimiter = \",\")\n",
        "  for row in reader:\n",
        "    if (row[4] == \"Solo Piano\"):\n",
        "      piano_pieces.append(row[0])\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "print(piano_pieces)\n",
        "print(len(piano_pieces))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ5FZzG9RJqV"
      },
      "source": [
        "# Create dataset 3D list\n",
        "train_dir = \"/content/musicnet/train_labels\"\n",
        "train_data_matrix = []\n",
        "for filename in os.listdir(train_dir):\n",
        "  if (os.path.join(filename[0:4]) in piano_pieces):\n",
        "    with open(os.path.join(train_dir, filename)) as max_file:\n",
        "      max_reader = csv.reader(max_file, delimiter = \",\")\n",
        "      next(max_reader)\n",
        "      start_times = []\n",
        "      end_times = []\n",
        "      notes = []\n",
        "      start_beats = []\n",
        "      end_beats = []\n",
        "      note_values = []\n",
        "      for row in max_reader:\n",
        "        start_times.append(float(row[0]))\n",
        "        end_times.append(float(row[1]))\n",
        "        start_beats.append(float(row[4]))\n",
        "        end_beats.append(float(row[5]))\n",
        "      max_start_time = max(start_times)\n",
        "      max_end_time = max(end_times)\n",
        "      max_start_beat = max(start_beats)\n",
        "      max_end_beat = max(end_beats)\n",
        "\n",
        "    with open(os.path.join(train_dir, filename)) as training_file:\n",
        "      reader = csv.reader(training_file, delimiter = \",\")\n",
        "      next(reader)\n",
        "      example_matrix = []\n",
        "      train_note_label = []\n",
        "      train_start_time = []\n",
        "      train_end_time = []\n",
        "      train_note = []\n",
        "      train_start_beat = []\n",
        "      train_end_beat = []\n",
        "      train_note_value = []\n",
        "      i = 0\n",
        "      for row in reader:\n",
        "        train_note_label.append(i)\n",
        "        train_start_time.append(float(row[0]) / max_start_time)\n",
        "        train_end_time.append(float(row[1]) / max_end_time)\n",
        "        train_note.append(float(row[3]))\n",
        "        train_start_beat.append(float(row[4]) / max_start_beat)\n",
        "        train_end_beat.append(float(row[5]) / max_end_beat)\n",
        "        if (row[6] == \"Whole\"):\n",
        "          train_note_value.append(1)\n",
        "        elif (row[6] == \"Dotted Half\"):\n",
        "          train_note_value.append(1.5 * (1/2))\n",
        "        elif (row[6] == \"Half\"):\n",
        "          train_note_value.append(1/2)\n",
        "        elif (row[6] == \"Dotted Quarter\"):\n",
        "          train_note_value.append(1.5 * (1/4))\n",
        "        elif (row[6] == \"Quarter\"):\n",
        "          train_note_value.append(1/4)\n",
        "        elif (row[6] == \"Triplet Quarter\"):\n",
        "          train_note_value.append((1/2) / 3)\n",
        "        elif (row[6] == \"Dotted Eighth\"):\n",
        "          train_note_value.append(1.5 * (1/8))\n",
        "        elif (row[6] == \"Eighth\"):\n",
        "          train_note_value.append(1/8)\n",
        "        elif (row[6] == \"Triplet Eighth\"):\n",
        "          train_note_value.append((1/4) / 3)\n",
        "        elif (row[6] == \"Dotted Sixteenth\"):\n",
        "          train_note_value.append(1.5 * (1/16))\n",
        "        elif (row[6] == \"Sixteenth\"):\n",
        "          train_note_value.append(1/16)\n",
        "        elif (row[6] == \"Triplet Sixteenth\"):\n",
        "          train_note_value.append((1/8) / 3)\n",
        "        elif (row[6] == \"Dotted Thirty Second\"):\n",
        "          train_note_value.append(1.5 * (1/32))\n",
        "        elif (row[6] == \"Thirty Second\"):\n",
        "          train_note_value.append(1/32)\n",
        "        elif (row[6] == \"Triplet Thirty Second\"):\n",
        "          train_note_value.append((1/16) / 3)\n",
        "        elif (row[6] == \"Dotted Sixty Fourth\"):\n",
        "          train_note_value.append(1.5 * (1/64))\n",
        "        elif (row[6] == \"Sixty Fourth\"):\n",
        "          train_note_value.append(1/64)\n",
        "        elif (row[6] == \"Triplet Sixty Fourth\"):\n",
        "          train_note_value.append((1/32) / 3)\n",
        "        elif (row[6] == \"Triplet\"):\n",
        "          train_note_value.append((1/4) / 3)\n",
        "        elif (row[6] == \"Unknown\"):\n",
        "          train_note_value.append(0)\n",
        "        elif (row[6][0:4] == \"Tied\"):\n",
        "          note = row[6].split()\n",
        "          value = note[1].split(\"-\")\n",
        "          first = value[0]\n",
        "          second = value[1]\n",
        "          first_value = 0\n",
        "          second_value = 0\n",
        "          if (first == \"Whole\"):\n",
        "            first_value = (1)\n",
        "          elif (first == \"Dotted Half\"):\n",
        "            first_value = (1.5 * (1/2))\n",
        "          elif (first == \"Half\"):\n",
        "            first_value = (1/2)\n",
        "          elif (first == \"Dotted Quarter\"):\n",
        "            first_value = (1.5 * (1/4))\n",
        "          elif (first == \"Quarter\"):\n",
        "            first_value = (1/4)\n",
        "          elif (first == \"Triplet Quarter\"):\n",
        "            first_value = ((1/2) / 3)\n",
        "          elif (first == \"Dotted Eighth\"):\n",
        "            first_value = (1.5 * (1/8))\n",
        "          elif (first == \"Eighth\"):\n",
        "            first_value = (1/8)\n",
        "          elif (first == \"Triplet Eighth\"):\n",
        "            first_value = ((1/4) / 3)\n",
        "          elif (first == \"Dotted Sixteenth\"):\n",
        "            first_value = (1.5 * (1/16))\n",
        "          elif (first == \"Sixteenth\"):\n",
        "            first_value = (1/16)\n",
        "          elif (first == \"Triplet Sixteenth\"):\n",
        "            first_value = ((1/8) / 3)\n",
        "          elif (first == \"Dotted Thirty Second\"):\n",
        "            first_value = (1.5 * (1/32))\n",
        "          elif (first == \"Thirty Second\"):\n",
        "            first_value = (1/32)\n",
        "          elif (first == \"Triplet Thirty Second\"):\n",
        "            first_value = ((1/16) / 3)\n",
        "          elif (first == \"Dotted Sixty Fourth\"):\n",
        "            first_value = (1.5 * (1/64))\n",
        "          elif (first == \"Sixty Fourth\"):\n",
        "            first_value = (1/64)\n",
        "          elif (first == \"Triplet Sixty Fourth\"):\n",
        "            first_value = ((1/32) / 3)\n",
        "            \n",
        "          if (second == \"Whole\"):\n",
        "            second_value = (1)\n",
        "          elif (second == \"Dotted Half\"):\n",
        "            second_value = (1.5 * (1/2))\n",
        "          elif (second == \"Half\"):\n",
        "            second_value = (1/2)\n",
        "          elif (second == \"Dotted Quarter\"):\n",
        "            second_value = (1.5 * (1/4))\n",
        "          elif (second == \"Quarter\"):\n",
        "            second_value = (1/4)\n",
        "          elif (second == \"Triplet Quarter\"):\n",
        "            second_value = ((1/2) / 3)\n",
        "          elif (second == \"Dotted Eighth\"):\n",
        "            second_value = (1.5 * (1/8))\n",
        "          elif (second == \"Eighth\"):\n",
        "            second_value = (1/8)\n",
        "          elif (second == \"Triplet Eighth\"):\n",
        "            second_value = ((1/4) / 3)\n",
        "          elif (second == \"Dotted Sixteenth\"):\n",
        "            second_value = (1.5 * (1/16))\n",
        "          elif (second == \"Sixteenth\"):\n",
        "            second_value = (1/16)\n",
        "          elif (second == \"Triplet Sixteenth\"):\n",
        "            second_value = ((1/8) / 3)\n",
        "          elif (second == \"Dotted Thirty Second\"):\n",
        "            second_value = (1.5 * (1/32))\n",
        "          elif (second == \"Thirty Second\"):\n",
        "            second_value = (1/32)\n",
        "          elif (second == \"Triplet Thirty Second\"):\n",
        "            second_value = ((1/16) / 3)\n",
        "          elif (second == \"Dotted Sixty Fourth\"):\n",
        "            second_value = (1.5 * (1/64))\n",
        "          elif (second == \"Sixty Fourth\"):\n",
        "            second_value = (1/64)\n",
        "          elif (second == \"Triplet Sixty Fourth\"):\n",
        "            second_value = ((1/32) / 3)\n",
        "\n",
        "          train_note_value.append(first_value + second_value)\n",
        "        else:\n",
        "          print(row[6])\n",
        "        i += 1\n",
        "      example_matrix.append(train_note_label)\n",
        "      example_matrix.append(train_start_time)\n",
        "      example_matrix.append(train_end_time)\n",
        "      example_matrix.append(train_note)\n",
        "      example_matrix.append(train_start_beat)\n",
        "      example_matrix.append(train_end_beat)\n",
        "      example_matrix.append(train_note_value)\n",
        "    train_data_matrix.append(example_matrix)\n",
        "    \n",
        "print(len(train_data_matrix), len(train_data_matrix[0]), len(train_data_matrix[0][0]))\n",
        "train_examples = len(train_data_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh07rx6F9siR"
      },
      "source": [
        "# Maximum number of notes in set of pieces\n",
        "train_dir = \"/content/musicnet/train_labels\"\n",
        "row_counts = []\n",
        "for filename in os.listdir(train_dir):\n",
        "  if (os.path.join(filename[0:4]) in piano_pieces):\n",
        "    with open(os.path.join(train_dir, filename)) as training_file:\n",
        "      reader = csv.reader(training_file, delimiter = \",\")\n",
        "      next(reader)\n",
        "      data = list(reader)\n",
        "      count = 0\n",
        "      count = len(data)\n",
        "      row_counts.append(count)\n",
        "max_dim = max(row_counts)\n",
        "print(max_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAFvKJtC8nJC"
      },
      "source": [
        "# Create and save dataset array\n",
        "train_data = np.empty((7, max_dim, train_examples))\n",
        "for i in range(train_examples):\n",
        "  reference = np.zeros((7, max_dim))\n",
        "  example_matrix = train_data_matrix[i][:][:]\n",
        "  example_matrix = np.array(example_matrix)\n",
        "  reference[:, :example_matrix.shape[1]] = example_matrix\n",
        "  train_data[:, :, i] = reference\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(path)\n",
        "np.save(\"train_data_array\", train_data)\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# train_data = tf.constant(train_data)\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAPuQDs5tz5"
      },
      "source": [
        "# Initialize and save categories\n",
        "os.chdir(\"/content\")\n",
        "categories_source = initialize(10000)\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(path)\n",
        "np.save(\"categories_source\", categories_source)\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB_S9TUdqML4"
      },
      "source": [
        "#**Feature Creation and Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoHadPufqayF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdLpzeIffO9"
      },
      "source": [
        "#**Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WxRKskZeEE0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math\n",
        "import os, csv, shutil\n",
        "import time\n",
        "!pip install -q GPUtil\n",
        "import io, psutil, GPUtil\n",
        "!pip install -q wandb\n",
        "import wandb\n",
        "from numba import jit, prange, cuda\n",
        "import cProfile\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpWwLZuHeokK"
      },
      "source": [
        "# Initialize weight vectors randomly\n",
        "def initialize(x):\n",
        "  categories = np.zeros((x, 7))\n",
        "  for i in range(x):\n",
        "    rand_vec = np.random.rand(7)\n",
        "    rand_vec[0] = i\n",
        "    categories[i] = rand_vec\n",
        "      \n",
        "  return categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nIrEKaOwW7"
      },
      "source": [
        "# Copy files to local environment\n",
        "os.chdir(\"/content\")\n",
        "train_source = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\", \"train_data_array_source.npy\")\n",
        "train_destination = os.path.join(os.getcwd(), \"train_data_array.npy\")\n",
        "copy = shutil.copyfile(train_source, train_destination)\n",
        "with open(\"train_data_array.npy\", \"rb\") as array:\n",
        "  train_data = np.load(array)\n",
        "print(train_data.shape)\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "categories = initialize(10000)\n",
        "print(categories.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDKz6zaug9nZ"
      },
      "source": [
        "# Define self organizing map\n",
        "\n",
        "# Create list of random inputs\n",
        "@jit\n",
        "def get_picks(train_data, epochs):\n",
        "  picks = np.zeros((epochs, train_data.shape[0]))\n",
        "  i = 0\n",
        "  while i < epochs:\n",
        "    x = random.randint(0, train_data.shape[1] - 1)\n",
        "    layer = random.randint(0, train_data.shape[2] - 1)\n",
        "    input_vec = np.array(train_data[:, x, layer])\n",
        "    if (input_vec[6] == 0):\n",
        "      continue\n",
        "    picks[i] = input_vec\n",
        "    i += 1\n",
        "    if i % 10000 == 0:\n",
        "      print(\"Iteration\", i)\n",
        "      \n",
        "  return picks\n",
        "\n",
        "\"\"\"     ▼ ▼ ▼     CPU version of pick_weight     ▼ ▼ ▼     \"\"\"\n",
        "\n",
        "@jit\n",
        "def euclidean_distance(vec1, vec2, features):\n",
        "  diffs_sum = 0\n",
        "  for i in features:\n",
        "    diffs_sum += (vec1[i] - vec2[i]) ** 2\n",
        "  dist = diffs_sum ** .5\n",
        "\n",
        "  return dist\n",
        "\n",
        "@jit\n",
        "def fast_distance(vec1, vec2, features):\n",
        "  diffs_sum = 0\n",
        "  for i in features:\n",
        "    diff = vec1[i] - vec2[i]\n",
        "    if diff < 0:\n",
        "      diff = -diff\n",
        "    diffs_sum += diff\n",
        "\n",
        "  return diffs_sum\n",
        "\n",
        "@jit(parallel = True)\n",
        "def pick_weight_cpu(categories, features, input_vec):\n",
        "  diffs = np.zeros((categories.shape[0], 2))\n",
        "  for i in prange(categories.shape[0]):\n",
        "    euclidean_dist = fast_distance(input_vec, categories[i], features)\n",
        "    diffs[i][0] = euclidean_dist\n",
        "    diffs[i][1] = categories[i][0]\n",
        "  min_label = distances(diffs)\n",
        "  winner = categories[min_label]\n",
        "\n",
        "  return input_vec, winner\n",
        "\n",
        "\"\"\"     ▲ ▲ ▲     CPU version of pick_weight     ▲ ▲ ▲     \"\"\"\n",
        "\n",
        "# Compare input vector to all categories\n",
        "@cuda.jit\n",
        "def compare(input_vec, categories, diffs, features):\n",
        "  i = cuda.grid(1)\n",
        "  if i < categories.shape[0]:\n",
        "    diffs_sum = 0\n",
        "    distance = 0\n",
        "    for j in features:\n",
        "      diff = input_vec[j] - categories[i][j]\n",
        "      if diff < 0:\n",
        "        diff = -diff\n",
        "      diffs_sum += diff\n",
        "    distance = diffs_sum\n",
        "    diffs[i][0] = distance\n",
        "    diffs[i][1] = categories[i][0]\n",
        "\n",
        "# Compare input vector to all categories - slower version with full distance calculation\n",
        "@cuda.jit\n",
        "def compare_euclidean(input_vec, categories, diffs, features):\n",
        "  i = cuda.grid(1)\n",
        "  if i < categories.shape[0]:\n",
        "    diffs_sum = 0\n",
        "    euclidean_distance = 0\n",
        "    for j in features:\n",
        "      diffs_sum += (input_vec[j] - categories[i][j]) ** 2\n",
        "    euclidean_distance = diffs_sum ** .5\n",
        "    diffs[i][0] = euclidean_distance\n",
        "    diffs[i][1] = categories[i][0]\n",
        "\n",
        "# Find smallest distance among distances\n",
        "@jit\n",
        "def distances(diffs):\n",
        "  min_diff = 100000\n",
        "  for i in range(0, diffs.shape[0]):\n",
        "    if diffs[i][0] < min_diff:\n",
        "      min_diff = diffs[i][0]\n",
        "      index = int(diffs[i][1])\n",
        "      \n",
        "  return index\n",
        "\n",
        "# Pick winner vector (BMU)\n",
        "@jit\n",
        "def pick_weight_gpu(categories, features, input_vec):\n",
        "  threads = 32\n",
        "  blocks = (categories.shape[0] + (threads - 1)) // threads\n",
        "  diffs = np.zeros((categories.shape[0], 2))\n",
        "  compare[blocks, threads](input_vec, categories, diffs, features)\n",
        "  min_label = distances(diffs)\n",
        "  winner = categories[min_label]\n",
        "\n",
        "  return input_vec, winner\n",
        "\n",
        "# Update learning rate\n",
        "@cuda.jit\n",
        "def alpha_decay(initial_alpha, epochs, alphas, k):\n",
        "  i = cuda.grid(1)\n",
        "  if i < epochs:\n",
        "    alphas[i] = initial_alpha * math.exp(-i/k)\n",
        "\n",
        "def get_alphas(epochs, initial_alpha, k):\n",
        "  alphas = np.array([0.0] * epochs)\n",
        "  threads = 32\n",
        "  blocks = (epochs + (threads - 1)) // threads\n",
        "  alpha_decay[blocks, threads](initial_alpha, epochs, alphas, k)\n",
        "\n",
        "  return alphas\n",
        "\n",
        "# Update neighborhood size\n",
        "@cuda.jit\n",
        "def neighborhood_update(initial_sigma, epochs, sigmas, k):\n",
        "  i = cuda.grid(1)\n",
        "  if i < epochs:\n",
        "    sigmas[i] = initial_sigma * math.exp(-i/k)\n",
        "\n",
        "def get_sigmas(epochs, initial_sigma, k):\n",
        "  sigmas = np.array([0.0] * epochs)\n",
        "  threads = 32\n",
        "  blocks = (epochs + (threads - 1)) // threads\n",
        "  neighborhood_update[blocks, threads](initial_sigma, epochs, sigmas, k)\n",
        "\n",
        "  return sigmas\n",
        "\n",
        "\"\"\"     ▼ ▼ ▼     CPU version of update_weights     ▼ ▼ ▼     \"\"\"\n",
        "\n",
        "# Calculate lattice distance between vectors (euclidean distance)\n",
        "@jit\n",
        "def lattice_dist(win_vec, weight, features):\n",
        "  diffs_sum = 0\n",
        "  for i in features:\n",
        "    diffs_sum += (win_vec[i] - weight[i]) ** 2\n",
        "  lattice_dist = diffs_sum ** .5\n",
        "\n",
        "  return lattice_dist\n",
        "\n",
        "@jit(parallel = True)\n",
        "def get_neighbors(categories, winner, features, sigma):\n",
        "  neighbors = np.zeros((categories.shape[0], categories.shape[1]))\n",
        "  counter = 0\n",
        "  for i in prange(0, categories.shape[0]):\n",
        "    if (lattice_dist(categories[i], winner, features) < sigma):\n",
        "      neighbors[counter] = categories[i]\n",
        "      counter += 1\n",
        "  for j in range(0, neighbors.shape[0]):\n",
        "    if neighbors[j][6] == 0:\n",
        "      neighbors = neighbors[0:j, :]\n",
        "      break\n",
        "      \n",
        "  return neighbors\n",
        "  \n",
        "@jit(parallel = True)\n",
        "def update_weights_cpu(learning_rate, sigma, winner, input_vec, categories, features):\n",
        "  neighbors = get_neighbors(categories, winner, features, sigma)\n",
        "  \n",
        "  for i in prange(0, neighbors.shape[0]):\n",
        "    d = lattice_dist(winner, neighbors[i], features)\n",
        "    kernel_func = math.exp((-d ** 2) / (2 * (sigma ** 2)))\n",
        "    label_placeholder = categories[i][0]\n",
        "    categories[i] = neighbors[i] + learning_rate * kernel_func * (input_vec - categories[i])\n",
        "    categories[i][0] = label_placeholder\n",
        "\n",
        "\"\"\"     ▲ ▲ ▲     CPU version of update_weights     ▲ ▲ ▲     \"\"\"\n",
        "\n",
        "# Find neighbor vectors\n",
        "@cuda.jit\n",
        "def neighbors_list(neighbors, categories, winner, sigma, input_vec, features):\n",
        "  i = cuda.grid(1)\n",
        "  counter = 0\n",
        "  if i < (categories.shape[0]):\n",
        "    diffs_sum = 0\n",
        "    lattice_dist = 0\n",
        "    # Lattice distance calculation in-line\n",
        "    for j in features:\n",
        "      diffs_sum += (categories[i][j] - winner[j]) ** 2\n",
        "    lattice_dist = diffs_sum ** .5\n",
        "    if (lattice_dist < sigma):\n",
        "      for k in range(0, categories[i].shape[0]):\n",
        "        neighbors[counter][k] = categories[i][k]\n",
        "      counter += 1\n",
        "\n",
        "# Update categories\n",
        "@cuda.jit\n",
        "def update_categories(categories, neighbors, winner, sigma, learning_rate, input_vec, features):\n",
        "  i = cuda.grid(1)\n",
        "  if i < neighbors.shape[0]:\n",
        "    # Lattice distance calculation in-line\n",
        "    diffs_sum = 0\n",
        "    for j in features:\n",
        "      diffs_sum += (winner[j] - neighbors[i][j]) ** 2\n",
        "    d = diffs_sum ** .5\n",
        "    kernel_func = math.exp((-d ** 2) / (2 * (sigma ** 2)))\n",
        "    cat_copy = categories[i]\n",
        "    for k in features:\n",
        "      cat_copy[k] = input_vec[k] - cat_copy[k]\n",
        "    for l in features:\n",
        "      categories[i][l] = neighbors[i][l] + learning_rate * kernel_func * cat_copy[l]\n",
        "\n",
        "@jit\n",
        "def update_weights_gpu(learning_rate, sigma, winner, input_vec, categories, features):\n",
        "  threads = 32\n",
        "  blocks = (categories.shape[0] + (threads - 1)) // threads\n",
        "  neighbors = np.zeros((categories.shape[0], categories.shape[1]))\n",
        "  neighbors_list[blocks, threads](neighbors, categories, winner, sigma, input_vec, features)\n",
        "  for i in range(0, neighbors.shape[0]):\n",
        "    if neighbors[i][6] == 0:\n",
        "      neighbors = neighbors[0:i, :]\n",
        "      break\n",
        "  \n",
        "  threads = 32\n",
        "  blocks = (neighbors.shape[0] + (threads - 1)) // threads\n",
        "  update_categories[blocks, threads](categories, neighbors, winner, sigma, learning_rate, input_vec, features)\n",
        "\n",
        "# Overall update rule\n",
        "def update(epochs, train_data, categories, initial_alpha, a_decay, s_decay, initial_sigma, features, mode):\n",
        "  path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "  os.chdir(path)\n",
        "  t0 = time.time()\n",
        "\n",
        "  alphas = get_alphas(epochs, initial_alpha, a_decay)\n",
        "  sigmas = get_sigmas(epochs, initial_sigma, s_decay)\n",
        "\n",
        "  picks = get_picks(train_data, epochs)\n",
        "\n",
        "  if mode == \"cpu\":\n",
        "    for i in range(epochs):\n",
        "      input_vec, winner = pick_weight_cpu(categories, features, picks[i])\n",
        "      update_weights_cpu(alphas[i], sigmas[i], winner, input_vec, categories, features)\n",
        "      if (i != 0):\n",
        "        if (i % 100 == 0):\n",
        "          mem = dict(psutil.virtual_memory()._asdict())\n",
        "          gpu = GPUtil.getGPUs()[0]\n",
        "          print(\"Iteration\", i, \"completed! Progress:\", \"%.2f\" % float(100 * (i / epochs)), \"%\",\n",
        "                \"    CPU: %.1f\" % psutil.cpu_percent(), \"%\",\n",
        "                \" RAM: %.1f\" % mem[\"percent\"], \"%\",\n",
        "                \" GPU: %.1f\" % (gpu.load * 100), \"%\",\n",
        "                \" VRAM: %.1f\" % (100 * gpu.memoryUsed / gpu.memoryFree), \"%\",\n",
        "                \"    Time remaining: %.1f\" % ((((time.time() - t0) / i) * epochs) / 60), \"m\")\n",
        "\n",
        "      # Prevent output from getting too long\n",
        "      t1 = time.time()\n",
        "      if int(t1 - t0) % 60 == 0:\n",
        "        clear_output()\n",
        "      # 8 hour time limit\n",
        "      if t1 - t0 > 28800:\n",
        "        np.save(\"categories\", categories)\n",
        "  \n",
        "    np.save(\"categories\", categories)\n",
        "    os.chdir(\"/content\")\n",
        "\n",
        "  if mode == \"gpu\":\n",
        "    picks = cuda.to_device(picks)\n",
        "    alphas = cuda.to_device(alphas)\n",
        "    sigmas = cuda.to_device(sigmas)\n",
        "    features = cuda.to_device(features)\n",
        "\n",
        "    for j in range(epochs):\n",
        "      input_vec, winner = pick_weight_gpu(categories, features, picks[j])\n",
        "      update_weights_gpu(alphas[j], sigmas[j], winner, input_vec, categories, features)\n",
        "      if (j != 0):\n",
        "        if (j % 100 == 0):\n",
        "          mem = dict(psutil.virtual_memory()._asdict())\n",
        "          gpu = GPUtil.getGPUs()[0]\n",
        "          print(\"Iteration\", j, \"completed! Progress:\", \"%.2f\" % float(100 * (j / epochs)), \"%\",\n",
        "                \"    CPU: %.1f\" % psutil.cpu_percent(), \"%\",\n",
        "                \" RAM: %.1f\" % mem[\"percent\"], \"%\",\n",
        "                \" GPU: %.1f\" % (gpu.load * 100), \"%\",\n",
        "                \" VRAM: %.1f\" % (100 * gpu.memoryUsed / gpu.memoryFree), \"%\",\n",
        "                \"    Time remaining: %.1f\" % ((((time.time() - t0) / j) * epochs) / 60), \"m\")\n",
        "\n",
        "      # Prevent output from getting too long\n",
        "      t1 = time.time()\n",
        "      if int(t1 - t0) % 60 == 0:\n",
        "        clear_output()\n",
        "      # 8 hour time limit\n",
        "      if t1 - t0 > 28800:\n",
        "        np.save(\"categories\", categories)\n",
        "  \n",
        "    np.save(\"categories\", categories)\n",
        "    os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_HbtLodau4I"
      },
      "source": [
        " \n",
        "To-do:\n",
        "- LSTM-like feature to take into account nearby notes\n",
        "- create more features/parameters\n",
        "- adjust distance calculations (use relative note length instead of start/end time, etc)\n",
        "- use other distance calculations (such that it doesn't pool all features into one metric)\n",
        "- implement pipeline, other performance improvements\n",
        "- data normalization\n",
        "- expand dataset\n",
        "- tune parameters (k, alpha, neighborhood size, lattice distance calculation (in both function and in-line update_categories), epochs)\n",
        "- adjust categories initialization to match input range\n",
        "- try different architectures (use LSTM for separate classification, include in SOM, use later in recording analysis, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKvP_TSj2toN"
      },
      "source": [
        "# Run SOM\n",
        " \n",
        "# Features list\n",
        "features = np.array([1, 2, 3, 4, 5, 6])\n",
        " \n",
        "os.chdir(\"/content\")\n",
        "wandb.init()\n",
        "cuda.profile_start()\n",
        "cProfile.run(\"update(400000, train_data, categories, 5, 100, 7500, 7500, features, 'cpu')\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQAaH4RlPpf"
      },
      "source": [
        "# Define self organizing map - Tensorflow implementation\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0vXhIZnAKjZ"
      },
      "source": [
        "# Show metrics for SOM\n",
        "@cuda.jit\n",
        "def metrics(categories):\n",
        "  matches = []\n",
        "  diffs = []\n",
        "  avgs = []\n",
        "\n",
        "  for i in range(categories.shape[0]):\n",
        "    matches.append([])\n",
        "    diffs.append([])\n",
        "    avgs.append([])\n",
        "\n",
        "  t0 = time.time()\n",
        "  counter = 0\n",
        "  for j in range(train_data.shape[1]):\n",
        "    for k in range(train_data.shape[2]):\n",
        "\n",
        "      counter += 1\n",
        "      if (counter % 100 == 0):\n",
        "        print(\"Iteration \", counter, \" completed!    Progress:\", \n",
        "              \"%.2f\" % float(100 * (counter / (train_data.shape[1] * train_data.shape[2]))), \"%\")\n",
        "      t1 = time.time()\n",
        "      if int(t1 - t0) % 60 == 0:\n",
        "        clear_output()\n",
        "\n",
        "      diffs = []\n",
        "      for l in range(categories.shape[0]):\n",
        "        euclidean_dist = 0\n",
        "        euclidean_dist = euclidean_distance(train_data[:, j, k], categories[l])\n",
        "        euclidean_dist_info = [euclidean_dist, categories[l][0]]\n",
        "        diffs.append(euclidean_dist_info)\n",
        "\n",
        "      min_diff = min(diffs)\n",
        "      min_index = diffs.index(min_diff)\n",
        "      min_label = diffs[min_index][1]\n",
        "\n",
        "      matches[int(min_label)].append(train_data[:, j, k])\n",
        "      diffs[int(min_label)].append(euclidean_dist)\n",
        "\n",
        "  for m in range(len(diffs)):\n",
        "    diff_sum = sum(diffs[m])\n",
        "    avg = diff_sum / len(diffs[m])\n",
        "    avgs[m].append(avg)\n",
        "\n",
        "  overall_sum = 0\n",
        "  for n in range(len(avgs)):\n",
        "    overall_sum += avgs[n]\n",
        "  overall_avg = overall_sum / len(avgs)\n",
        "\n",
        "  return overall_avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At84S0OlQFAv"
      },
      "source": [
        "# Load trained categories file\n",
        "os.chdir(\"/content\")\n",
        "path = os.path.join(os.getcwd(), \"drive\", \"My Drive\", \"AI Music Synthesizer\")\n",
        "os.chdir(path)\n",
        "with open(\"categories.npy\", \"rb\") as array:\n",
        "  categories = np.load(array)\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2TJgN4DIeMq"
      },
      "source": [
        "# Show metrics for categories\n",
        "metrics(categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRhPf2vXqzea"
      },
      "source": [
        "# Parameter tuning\n",
        "#categories, alpha, sigma, decay constant\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}